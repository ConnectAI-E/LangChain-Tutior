1
00:00:01,000 --> 00:00:16,000
当使用llm构建复杂应用程序时，评估应用程序的表现是一个重要但有时棘手的步骤。它是否满足某些准确性标准？

2
00:00:16,000 --> 00:00:33,000
此外，如果您决定更改实现，可能会交换不同的llm或更改如何使用矢量数据库或其他内容检索通道或更改系统的某些其他参数的策略，那么如何知道您是在使其变得更好还是更糟？

3
00:00:34,000 --> 00:00:42,000
在本视频中，哈里森将深入探讨一些框架，以思考如何评估基于llm的应用程序以及一些工具来帮助您做到这一点。

4
00:00:42,000 --> 00:00:53,000
这些应用程序实际上是许多不同步骤的链和序列。因此，老实说，您应该做的第一件事就是了解每个步骤的具体情况。

5
00:00:54,000 --> 00:00:58,000
因此，一些工具实际上可以被视为可视化器或调试器。

6
00:00:59,000 --> 00:01:04,000
但是，通常更有用的是从许多不同的数据点中获得更全面的模型表现情况。

7
00:01:04,000 --> 00:01:15,000
一种方法是通过肉眼观察来做到这一点。但是，还有这个非常酷的想法，即使用语言模型本身和链本身来评估其他语言模型、其他链和其他应用程序。

8
00:01:16,000 --> 00:01:17,000
我们也将深入探讨这个想法。

9
00:01:18,000 --> 00:01:30,000
因此，有很多很酷的主题。我发现随着许多开发转向基于提示的开发，使用llm开发应用程序，整个工作流程评估过程正在被重新思考。

10
00:01:30,000 --> 00:01:34,000
因此，在本视频中有许多令人兴奋的概念。让我们开始吧。

11
00:01:35,000 --> 00:01:38,000
好的。那么，让我们开始评估。

12
00:01:39,000 --> 00:01:44,000
首先，我们需要有我们要评估的链或应用程序。

13
00:01:45,000 --> 00:01:49,000
我们将使用上一课的文档问答链。

14
00:01:50,000 --> 00:01:55,000
因此，我们将导入我们需要的所有内容。我们将加载相同的数据。

15
00:01:55,000 --> 00:01:58,000
我们将用一行代码创建该索引。

16
00:01:59,000 --> 00:02:11,000
然后，我们将通过指定语言模型、链类型、检索器和我们要打印的详细程度来创建检索QA链。

17
00:02:13,000 --> 00:02:14,000
因此，我们有了这个应用程序。

18
00:02:14,000 --> 00:02:25,000
我们需要做的第一件事是真正弄清楚我们想要评估它的一些数据点。
 
19
00:02:26,000 --> 00:02:29,000
因此，我们将介绍几种不同的方法来完成这个任务。

20
00:02:30,000 --> 00:02:37,000
第一种方法是最简单的，基本上我们将自己想出好的数据点作为例子。

21
00:02:37,000 --> 00:02:47,000
为此，我们可以查看一些数据，然后想出例子问题和答案，以便以后用于评估。

22
00:02:48,000 --> 00:02:55,000
因此，如果我们查看这里的一些文档，我们可以对其中发生的事情有所了解。

23
00:02:56,000 --> 00:03:01,000
看起来第一个文档中有这个套头衫，第二个文档中有这个夹克。

24
00:03:02,000 --> 00:03:05,000
它们都有很多细节。

25
00:03:05,000 --> 00:03:10,000
从这些细节中，我们可以创建一些例子查询和答案对。

26
00:03:11,000 --> 00:03:16,000
因此，我们可以问一个简单的问题，这个舒适的套头衫套装有侧口袋吗？

27
00:03:17,000 --> 00:03:22,000
我们可以通过上面的内容看到，它确实有一些侧口袋。

28
00:03:23,000 --> 00:03:29,000
然后对于第二个文档，我们可以看到这件夹克来自某个系列，即down tech系列。

29
00:03:30,000 --> 00:03:32,000
因此，我们可以问一个问题，这件夹克来自哪个系列？

30
00:03:32,000 --> 00:03:35,000
答案是down tech系列。

31
00:03:36,000 --> 00:03:38,000
因此，我们创建了两个例子。

32
00:03:39,000 --> 00:03:41,000
但这并不是很可扩展。

33
00:03:42,000 --> 00:03:45,000
需要花费一些时间查看每个例子并弄清楚发生了什么。

34
00:03:46,000 --> 00:03:48,000
因此，有没有一种方法可以自动化？

35
00:03:49,000 --> 00:03:53,000
我们认为可以使用语言模型本身来实现这一点。

36
00:03:54,000 --> 00:03:57,000
因此，我们在LangChain中有一个链可以做到这一点。

37
00:03:58,000 --> 00:04:00,000
因此，我们可以导入QA生成链。

38
00:04:00,000 --> 00:04:05,000
它将接收文档，并从每个文档中创建一个问题答案对。

39
00:04:06,000 --> 00:04:08,000
它将使用语言模型本身来完成这一点。

40
00:04:09,000 --> 00:04:13,000
因此，我们需要通过传递chat open AI语言模型来创建这个链。

41
00:04:14,000 --> 00:04:16,000
然后，我们可以创建许多例子。

42
00:04:17,000 --> 00:04:23,000
因此，我们将使用apply和parse方法，因为这将应用输出解析器到结果。

43
00:04:24,000 --> 00:04:27,000
因为我们想要得到一个具有查询和答案对的字典，

44
00:04:27,000 --> 00:04:29,000
而不仅仅是一个字符串。
 
45
00:04:36,000 --> 00:04:39,000
因此，现在如果我们看看这里返回了什么，

46
00:04:40,000 --> 00:04:42,000
我们可以看到一个查询和一个答案。

47
00:04:43,000 --> 00:04:46,000
让我们检查一下这是一个问题和答案的文档。

48
00:04:47,000 --> 00:04:49,000
我们可以看到它正在询问这个的重量。

49
00:04:50,000 --> 00:04:52,000
我们可以看到它正在从这里获取重量。

50
00:04:53,000 --> 00:04:54,000
看看那个。

51
00:04:54,000 --> 00:04:56,000
我们刚刚生成了一堆问题答案对。

52
00:04:57,000 --> 00:04:58,000
我们不必自己编写它们。

53
00:04:59,000 --> 00:05:02,000
节省了我们很多时间，我们可以做更有趣的事情。

54
00:05:03,000 --> 00:05:08,000
因此，现在让我们将这些示例添加到我们已经创建的示例中。

55
00:05:09,000 --> 00:05:14,000
所以，我们现在有了这些示例，但是我们如何评估正在发生的事情呢？

56
00:05:15,000 --> 00:05:18,000
我们想做的第一件事就是运行一个示例通过链

57
00:05:19,000 --> 00:05:21,000
并查看它产生的输出。

58
00:05:21,000 --> 00:05:25,000
因此，在这里我们传递一个查询，然后我们得到一个答案。

59
00:05:26,000 --> 00:05:29,000
但是这在了解链中实际发生的事情方面有点受限

60
00:05:30,000 --> 00:05:31,000
实际上正在发生的事情。

61
00:05:32,000 --> 00:05:34,000
进入语言模型的实际提示是什么？

62
00:05:35,000 --> 00:05:37,000
它检索的文档是什么？

63
00:05:38,000 --> 00:05:40,000
如果这是一个更复杂的链，其中有多个步骤，

64
00:05:41,000 --> 00:05:42,000
中间结果是什么？

65
00:05:43,000 --> 00:05:46,000
仅仅查看最终答案通常不足以了解链中出现了什么问题或可能出现了什么问题。

66
00:05:46,000 --> 00:05:50,000
为了帮助解决这个问题，我们在LingChain中有一个有趣的小工具，称为LingChainDebug。

67
00:05:51,000 --> 00:05:56,000
因此，如果我们将LingChainDebug设置为true

68
00:06:03,000 --> 00:06:06,000
现在我们重新运行与上面相同的示例，

69
00:06:07,000 --> 00:06:11,000
我们可以看到它开始打印出更多的信息。

70
00:06:12,000 --> 00:06:14,000
因此，如果我们看看它到底打印了什么，

71
00:06:14,000 --> 00:06:18,000
我们可以看到它首先深入到检索QA链中

72
00:06:19,000 --> 00:06:21,000
然后它进入了一些文档链。

73
00:06:22,000 --> 00:06:24,000
因此，如上所述，我们正在使用stuff方法。

74
00:06:25,000 --> 00:06:28,000
现在它正在进入LLM链，我们有几个不同的输入。

75
00:06:29,000 --> 00:06:31,000
因此，我们可以看到原始问题就在那里。

76
00:06:32,000 --> 00:06:33,000
现在我们正在传递这个上下文。
 
78
00:06:34,000 --> 00:06:36,000
我们可以看到，这个上下文是由我们检索到的不同文档创建的。

79
00:06:37,000 --> 00:06:40,000
因此，在进行问答时，当返回错误结果时，

80
00:06:41,000 --> 00:06:42,000
通常不是语言模型本身出错了。

81
00:06:42,000 --> 00:06:44,000
实际上是检索步骤出错了。

82
00:06:45,000 --> 00:06:48,000
因此，仔细查看问题的确切内容和上下文可以帮助调试出错的原因。

83
00:06:49,000 --> 00:06:50,000
然后，我们可以再向下一级

84
00:06:51,000 --> 00:06:54,000
看看进入语言模型的确切内容，

85
00:06:55,000 --> 00:06:58,000
以及 OpenAI 自身。

86
00:06:59,000 --> 00:07:01,000
因此，在这里，我们可以看到传递的完整提示。

87
00:07:02,000 --> 00:07:04,000
所以，我们有一个系统消息。

88
00:07:05,000 --> 00:07:06,000
我们有所使用的提示的描述。

89
00:07:07,000 --> 00:07:09,000
因此，这是问题回答链使用的提示，

90
00:07:09,000 --> 00:07:11,000
我们甚至直到现在都没有看过。

91
00:07:12,000 --> 00:07:14,000
因此，我们可以看到提示打印出来，

92
00:07:15,000 --> 00:07:17,000
使用以下上下文片段回答用户的问题。

93
00:07:18,000 --> 00:07:19,000
如果您不知道答案，只需说您不知道即可。

94
00:07:20,000 --> 00:07:21,000
不要试图编造答案。

95
00:07:22,000 --> 00:07:23,000
然后我们看到一堆之前插入的上下文，

96
00:07:24,000 --> 00:07:26,000
然后我们看到一个人类问题，

97
00:07:27,000 --> 00:07:28,000
也就是我们问它的问题。

98
00:07:29,000 --> 00:07:30,000
我们还可以看到有关实际返回类型的更多信息。

99
00:07:31,000 --> 00:07:33,000
因此，我们不仅仅返回一个字符串，

100
00:07:34,000 --> 00:07:35,000
我们还返回了许多信息，如令牌使用情况，

101
00:07:36,000 --> 00:07:37,000
因此，提示令牌、完成令牌、

102
00:07:38,000 --> 00:07:40,000
总令牌和模型名称。

103
00:07:41,000 --> 00:07:42,000
这可以非常有用地跟踪您在链中使用的令牌

104
00:07:43,000 --> 00:07:45,000
或随时间调用语言模型的令牌

105
00:07:46,000 --> 00:07:47,000
并跟踪总令牌数，

106
00:07:48,000 --> 00:07:50,000
这与总成本非常接近。

107
00:07:51,000 --> 00:07:53,000
由于这是一个相对简单的链，

108
00:07:54,000 --> 00:07:55,000
我们现在可以看到最终的响应，

109
00:07:56,000 --> 00:07:57,000
或者随时间调用语言模型

110
00:07:58,000 --> 00:07:59,000
并跟踪令牌的总数，

111
00:08:00,000 --> 00:08:02,000
这与总成本非常接近。

112
00:08:03,000 --> 00:08:05,000
由于这是一个相对简单的链，

113
00:08:05,000 --> 00:08:06,000
现在我们可以看到最终的响应，
 
114
00:08:07,000 --> 00:08:09,000
舒适的毛衣套装，条纹款，

115
00:08:10,000 --> 00:08:11,000
有侧袋，正在起泡，

116
00:08:12,000 --> 00:08:14,000
通过链条返回给用户。

117
00:08:15,000 --> 00:08:17,000
因此，我们刚刚讲解了如何查看和调试单个输入到该链的情况。

118
00:08:18,000 --> 00:08:21,000
但是我们创建的所有示例呢？

119
00:08:22,000 --> 00:08:23,000
我们该如何评估它们？

120
00:08:24,000 --> 00:08:25,000
与创建它们类似，

121
00:08:26,000 --> 00:08:28,000
一种方法是手动进行。

122
00:08:29,000 --> 00:08:30,000
我们可以运行链条来处理所有示例，

123
00:08:31,000 --> 00:08:32,000
然后查看输出并尝试弄清楚

124
00:08:32,000 --> 00:08:34,000
发生了什么，它是否正确，

125
00:08:35,000 --> 00:08:36,000
不正确，部分正确。

126
00:08:37,000 --> 00:08:38,000
与创建示例类似，

127
00:08:39,000 --> 00:08:40,000
随着时间的推移，这开始变得有点乏味。

128
00:08:41,000 --> 00:08:42,000
因此，让我们回到我们最喜欢的解决方案。

129
00:08:43,000 --> 00:08:45,000
我们可以要求语言模型来做吗？

130
00:08:46,000 --> 00:08:48,000
首先，我们需要为所有示例创建预测。

131
00:08:49,000 --> 00:08:51,000
在这之前，我要关闭

132
00:08:52,000 --> 00:08:54,000
调试模式，以便不将所有内容打印到屏幕上。

133
00:08:55,000 --> 00:08:57,000
然后我将为所有不同的示例创建预测。

134
00:08:58,000 --> 00:08:59,000
因此，我认为我们总共有七个示例。

135
00:09:00,000 --> 00:09:01,000
现在我们有了这些示例，

136
00:09:02,000 --> 00:09:03,000
我们可以考虑评估它们。

137
00:09:04,000 --> 00:09:06,000
因此，我们将导入QA，

138
00:09:07,000 --> 00:09:09,000
问题回答，评估链。

139
00:09:09,000 --> 00:09:29,000
我们将通过语言模型创建此链，

140
00:09:30,000 --> 00:09:31,000
因为我们将使用语言模型

141
00:09:32,000 --> 00:09:33,000
来帮助进行评估。

142
00:09:34,000 --> 00:09:35,000
然后我们将在此链上调用evaluate。

143
00:09:35,000 --> 00:09:38,000
我们将传入示例和预测，

144
00:09:39,000 --> 00:09:40,000
然后我们将得到一堆分级输出。

145
00:09:41,000 --> 00:09:42,000
因此，为了看到每个示例的情况，

146
00:09:43,000 --> 00:09:44,000
我们将使用一个语言模型

147
00:09:45,000 --> 00:09:50,000
来帮助进行评估。

148
00:09:51,000 --> 00:09:53,000
然后我们将在该模型上调用评估函数。

149
00:09:54,000 --> 00:09:56,000
我们将传入示例和预测结果，

150
00:09:57,000 --> 00:09:59,000
然后我们将获得一系列评分输出。

151
00:10:00,000 --> 00:10:03,000
因此，为了准确了解每个示例的情况，

152
00:10:03,000 --> 00:10:07,000
对于每个示例正在发生的情况，

153
00:10:07,000 --> 00:10:08,000
我们将循环遍历它们。

154
00:10:09,000 --> 00:10:10,000
我们将打印出问题。

155
00:10:11,000 --> 00:10:12,000
而且，这是由语言模型生成的。

156
00:10:13,000 --> 00:10:14,000
我们将打印出真正的答案。

157
00:10:15,000 --> 00:10:17,000
而且，这也是由语言模型生成的。

158
00:10:18,000 --> 00:10:19,000
当它面前有整个文档时，它可以生成一个真实的答案。

159
00:10:20,000 --> 00:10:22,000
因此，它可以生成一个真实的答案。

160
00:10:23,000 --> 00:10:24,000
我们将打印出预测的答案。

161
00:10:25,000 --> 00:10:26,000
这是由语言模型生成的。

162
00:10:27,000 --> 00:10:28,000
当它进行QA链时，

163
00:10:29,000 --> 00:10:30,000
当它使用嵌入和向量数据库进行检索时，

164
00:10:30,000 --> 00:10:32,000
然后将其传递到语言模型中，

165
00:10:33,000 --> 00:10:35,000
然后尝试猜测预测的答案。

166
00:10:36,000 --> 00:10:37,000
然后我们还将打印出成绩。

167
00:10:38,000 --> 00:10:40,000
而且，这也是由语言模型生成的

168
00:10:41,000 --> 00:10:43,000
当它要求评估链评估正在发生的事情时，

169
00:10:44,000 --> 00:10:45,000
以及它是否正确或不正确。

170
00:10:46,000 --> 00:10:47,000
因此，当我们循环遍历所有这些示例并将它们打印出来时，

171
00:10:48,000 --> 00:10:49,000
我们可以详细了解每个示例。

172
00:10:50,000 --> 00:10:53,000
对于每个示例，它看起来都是正确的。

173
00:10:54,000 --> 00:10:56,000
这是一个相对简单的检索问题，

174
00:11:00,000 --> 00:11:01,000
所以这是令人放心的。

175
00:11:02,000 --> 00:11:04,000
那么，让我们看看第一个例子。

176
00:11:05,000 --> 00:11:07,000
这里的问题是，舒适的套头衫套装

178
00:11:08,000 --> 00:11:09,000
有侧口袋吗？

179
00:11:10,000 --> 00:11:11,000
真正的答案，我们创建了这个，是肯定的。

180
00:11:12,000 --> 00:11:14,000
预测的答案，语言模型产生的，

181
00:11:15,000 --> 00:11:17,000
是舒适的套头衫套装条纹

182
00:11:18,000 --> 00:11:19,000
确实有侧口袋。

183
00:11:20,000 --> 00:11:22,000
因此，我们可以理解这是一个正确的答案。

184
00:11:22,000 --> 00:11:25,000
实际上，语言模型也是这样，

185
00:11:26,000 --> 00:11:27,000
它将其评为正确。

186
00:11:28,000 --> 00:11:29,000
但是让我们想想为什么我们需要使用

187
00:11:30,000 --> 00:11:31,000
语言模型首先。 

188
00:11:32,000 --> 00:11:35,000
这两个字符串实际上完全不同。

189
00:11:36,000 --> 00:11:37,000
它们非常不同。

190
00:11:38,000 --> 00:11:39,000
一个非常短，一个非常长。
 
191
00:11:40,000 --> 00:11:41,000
我甚至认为“是”的字眼都没有出现过。

192
00:11:42,000 --> 00:11:43,000
在这个字符串中。

193
00:11:44,000 --> 00:11:45,000
因此，如果我们尝试进行一些字符串匹配

194
00:11:46,000 --> 00:11:47,000
或精确匹配，甚至在这里使用一些正则表达式，

195
00:11:48,000 --> 00:11:49,000
它就不知道该怎么做了。

196
00:11:49,000 --> 00:11:51,000
它们不是同一件事。

197
00:11:52,000 --> 00:11:53,000
这显示了使用语言模型进行评估的重要性。

198
00:11:54,000 --> 00:11:55,000
你有这些答案，它们是任意的字符串。

199
00:11:56,000 --> 00:12:00,000
没有单一的真实字符串是最好的可能答案。

200
00:12:01,000 --> 00:12:03,000
有许多不同的变体。

201
00:12:04,000 --> 00:12:05,000
只要它们具有相同的语义意义，

202
00:12:06,000 --> 00:12:07,000
它们应该被评为相似。

203
00:12:08,000 --> 00:12:09,000
这就是语言模型的帮助所在，

204
00:12:10,000 --> 00:12:12,000
而不是仅仅进行精确匹配。

207
00:12:16,000 --> 00:12:19,000
这种比较字符串的困难是使语言模型评估变得如此困难的原因。

208
00:12:20,000 --> 00:12:23,000
我们正在将它们用于这些非常开放的任务

209
00:12:24,000 --> 00:12:26,000
其中它们被要求生成文本。

210
00:12:27,000 --> 00:12:28,000
这以前并没有真正做过，

211
00:12:29,000 --> 00:12:30,000
因为直到最近的模型还不够好

212
00:12:31,000 --> 00:12:32,000
来做到这一点。

213
00:12:33,000 --> 00:12:34,000
因此，到目前为止存在的许多评估指标都不够好。

214
00:12:35,000 --> 00:12:36,000
我们不得不发明新的指标

215
00:12:37,000 --> 00:12:38,000
和发明新的启发式方法来做到这一点。

216
00:12:39,000 --> 00:12:40,000
目前最有趣和最受欢迎的

219
00:12:44,000 --> 00:12:46,000
这些启发式方法之一

220
00:12:47,000 --> 00:12:49,000
实际上是使用语言模型进行评估。

221
00:12:50,000 --> 00:12:51,000
这结束了评估课程，

222
00:12:52,000 --> 00:12:53,000
但我想向您展示的最后一件事

223
00:12:54,000 --> 00:12:55,000
是LangChain评估平台。

224
00:12:56,000 --> 00:12:58,000
这是一种在笔记本中执行我们刚刚执行的所有操作的方法，但是将其持久化并在UI中显示。

225
00:12:59,000 --> 00:13:01,000
因此，让我们来看看。
 
230
00:13:09,000 --> 00:13:13,000
我们在笔记本中运行的所有运行。

231
00:13:14,000 --> 00:13:16,000
因此，这是跟踪输入和输出的好方法

232
00:13:17,000 --> 00:13:18,000
在高层次上，但这也是一种非常好的方式

233
00:13:19,000 --> 00:13:21,000
看看底层到底发生了什么。

234
00:13:22,000 --> 00:13:24,000
因此，这是在打开调试模式时打印出的相同信息

235
00:13:25,000 --> 00:13:26,000
在一个 UI 中可视化

236
00:13:27,000 --> 00:13:28,000
在一个更好的方式。

237
00:13:29,000 --> 00:13:31,000
因此，我们可以看到链的输入

238
00:13:32,000 --> 00:13:33,000
和每个步骤的链的输出。

239
00:13:34,000 --> 00:13:35,000
然后我们可以点击越来越深

240
00:13:36,000 --> 00:13:37,000
进入链并查看更多信息

241
00:13:37,000 --> 00:13:39,000
关于实际传递的内容。

242
00:13:40,000 --> 00:13:41,000
因此，如果我们一直走到底部，

243
00:13:42,000 --> 00:13:43,000
我们现在可以看到正在传递什么

244
00:13:44,000 --> 00:13:45,000
确切地到聊天模型。

245
00:13:46,000 --> 00:13:47,000
我们在这里有系统消息。

246
00:13:48,000 --> 00:13:49,000
我们在这里有人类问题。

247
00:13:50,000 --> 00:13:51,000
我们在这里有聊天模型的响应。

248
00:13:52,000 --> 00:13:53,000
我们有一些输出元数据。

249
00:13:54,000 --> 00:13:55,000
我们在这里添加的另一件事

250
00:13:56,000 --> 00:13:58,000
是能够将这些示例添加到数据集中。

251
00:13:59,000 --> 00:14:01,000
因此，如果您记得，当我们创建时

252
00:14:02,000 --> 00:14:03,000
那些示例数据集在开始时，

253
00:14:04,000 --> 00:14:05,000
我们部分手动创建，

254
00:14:05,000 --> 00:14:07,000
部分使用语言模型。

255
00:14:08,000 --> 00:14:09,000
在这里，我们可以通过单击此小按钮将其添加到数据集中，

256
00:14:10,000 --> 00:14:11,000
现在我们有输入查询

257
00:14:12,000 --> 00:14:13,000
和输出结果。

258
00:14:14,000 --> 00:14:15,000
因此，我们可以创建一个数据集。

261
00:14:20,000 --> 00:14:22,000
我们可以称其为深度学习。

262
00:14:25,000 --> 00:14:26,000
然后我们可以开始添加示例

263
00:14:27,000 --> 00:14:28,000
到这个数据集中。

264
00:14:29,000 --> 00:14:30,000
因此，回到最初的事情

265
00:14:31,000 --> 00:14:32,000
我们在课程开始时解决的问题，

266
00:14:32,000 --> 00:14:34,000
我们需要创建这些数据集

267
00:14:35,000 --> 00:14:36,000
以便我们可以进行评估。

268
00:14:37,000 --> 00:14:38,000
这是一种非常好的方式

269
00:14:39,000 --> 00:14:40,000
只是在后台运行。
 
270
00:14:41,000 --> 00:14:42,000
随着时间的推移，不断添加示例数据集

271
00:14:43,000 --> 00:14:44,000
开始建立这些示例

272
00:14:45,000 --> 00:14:46,000
您可以开始用于评估的示例

273
00:14:46,000 --> 00:15:05,000
并启动评估的飞轮。