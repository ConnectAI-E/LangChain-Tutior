
 
1
00:00:00,000 --> 00:00:08,720
在第一课中，我们将涵盖模型、提示和解析器。

2
00:00:08,720 --> 00:00:13,320
因此，模型是指支撑许多内容的语言模型。

3
00:00:13,320 --> 00:00:18,680
提示是指创建输入以传递到模型的样式。

4
00:00:18,680 --> 00:00:20,400
然后解析器位于相反的端点。

5
00:00:20,400 --> 00:00:24,360
它涉及将这些模型的输出解析为更结构化的格式，以便您可以在下游执行操作。

6
00:00:24,360 --> 00:00:27,360
因此，当您使用llm构建应用程序时，

7
00:00:27,360 --> 00:00:30,640
它们通常是可重用的模型。

8
00:00:30,640 --> 00:00:32,600
我们反复提示模型，

9
00:00:32,600 --> 00:00:34,160
解析输出，因此Lanchain提供了一组易于使用的抽象来执行此类操作。

10
00:00:34,160 --> 00:00:36,520
因此，让我们开始看一下模型、提示和解析器。

11
00:00:36,520 --> 00:00:39,760
因此，为了开始，

12
00:00:39,760 --> 00:00:44,640
这里有一些起始代码。

13
00:00:44,640 --> 00:00:46,160
我要导入OS，

14
00:00:46,160 --> 00:00:47,640
导入OpenAI，并加载我的OpenAI秘钥。

15
00:00:47,640 --> 00:00:48,840
OpenAI库已经安装在

16
00:00:48,840 --> 00:00:53,240
我的Jupyter笔记本环境中，因此如果您在本地运行此代码，

17
00:00:53,240 --> 00:00:56,400
并且您尚未安装OpenAI，

18
00:00:56,400 --> 00:00:59,920
您可能需要运行它。

19
00:00:59,920 --> 00:01:01,960
BangPip install OpenAI，但我不会在这里这样做。

20
00:01:01,960 --> 00:01:04,000
然后这是一个辅助函数。

21
00:01:04,000 --> 00:01:06,840
这实际上与您可能在

22
00:01:06,840 --> 00:01:08,720
ChatGPT提示工程师开发者课程中看到的辅助函数非常相似，

23
00:01:08,720 --> 00:01:10,280
所以使用这个辅助函数，

24
00:01:10,280 --> 00:01:13,960
您可以说get completion on，

25
00:01:13,960 --> 00:01:17,240
什么是1加1，这将调用ChatGPT或技术上的模型，

26
00:01:17,240 --> 00:01:20,360
GPT 3.5 Turbo，以便您可以得到这样的答案。

27
00:01:20,360 --> 00:01:22,160
因此，为了激发模型提示和解析器的线链抽象，

28
00:01:22,160 --> 00:01:25,200
让我们假设您收到一封来自客户的电子邮件，该电子邮件不是英语。

29
00:01:25,200 --> 00:01:31,120
为了确保这是可访问的，我将使用英语海盗语言。

30
00:01:31,120 --> 00:01:35,400
当客户说R时，
 
36
00:01:57,120 --> 00:02:02,280
我会因为搅拌机盖子飞出去，把我的厨房墙壁弄得满是果汁而感到愤怒。

37
00:02:02,280 --> 00:02:06,120
更糟糕的是，保修不包括清洁厨房的费用。

38
00:02:06,120 --> 00:02:08,000
我现在需要你的帮助，伙计。

39
00:02:08,000 --> 00:02:12,400
所以我们将要做的是请求这个LLM以平静和尊重的口吻将文本翻译成美式英语。

40
00:02:12,400 --> 00:02:18,080
所以我将把风格设置为平静和尊重的美式英语。

41
00:02:18,080 --> 00:02:22,520
为了实现这一点，我将使用一个f字符串来指定提示和指令。

42
00:02:22,520 --> 00:02:26,080
如果你之前看过一些提示，我将使用一个f字符串来指定提示和指令。

43
00:02:26,080 --> 00:02:29,080
我将指定用三个反引号括起来的文本翻译成指定的风格。

44
00:02:29,080 --> 00:02:33,040
然后插入这两种风格。

45
00:02:33,040 --> 00:02:38,160
这样就生成了一个提示，说要翻译文本等等。

46
00:02:38,160 --> 00:02:39,880
我鼓励你暂停视频并运行代码，尝试修改提示以查看是否可以获得不同的输出。

47
00:02:39,880 --> 00:02:46,200
然后，你可以提示大型语言模型以获得响应。

48
00:02:46,200 --> 00:02:49,840
让我们看看响应是什么。

53
00:03:04,320 --> 00:03:07,880
说将英语海盗的消息翻译成这个非常礼貌的语气。

54
00:03:07,880 --> 00:03:10,680
我真的很沮丧，因为我的搅拌机盖子飞了出去，

55
00:03:10,680 --> 00:03:13,480
把我的厨房墙壁弄得满是果汁等等。

56
00:03:13,480 --> 00:03:18,120
嗯，我现在真的需要你的帮助，我的朋友。听起来非常好。

57
00:03:18,120 --> 00:03:23,160
因此，如果你有不同语言的不同客户撰写评论，

58
00:03:23,160 --> 00:03:26,880
不仅仅是英语海盗，还有法语、德语、日语等等，

59
00:03:26,880 --> 00:03:29,800
你可以想象需要生成一整个提示序列来生成这样的翻译。

60
00:03:29,800 --> 00:03:33,920
让我们看看如何使用Lang chain更方便地完成这项工作。

61
00:03:33,920 --> 00:03:39,360
我将导入chat open AI。这是Lang chain对chat GPT API端点的抽象。

62
00:03:39,360 --> 00:03:44,360
因此，如果我设置chat等于chat open AI并查看chat是什么，

63
00:03:44,360 --> 00:03:49,320
它将创建这个对象，使用chat GPT模型，也称为GPT 3.5 turbo。

64
00:03:49,320 --> 00:03:53,840
当我构建应用程序时，
 
69
00:04:04,560 --> 00:04:09,560
我经常做的一件事是将温度参数设置为0。

70
00:04:09,560 --> 00:04:11,800
所以默认温度为0.7。

71
00:04:11,800 --> 00:04:20,040
但让我重新设置温度为0.0。

72
00:04:20,040 --> 00:04:25,400
现在将温度设置为0，以使我们输出的随机性稍微减少一些。

73
00:04:26,800 --> 00:04:30,960
现在让我按如下方式定义模板字符串。

74
00:04:30,960 --> 00:04:35,000
将由三个向量分隔的文本翻译成样式。

75
00:04:35,000 --> 00:04:36,800
然后这里是文本。

76
00:04:36,800 --> 00:04:40,320
为了反复重用这个模板，

77
00:04:40,320 --> 00:04:46,200
让我们导入Lang chain的聊天提示模板。

78
00:04:46,200 --> 00:04:54,840
然后让我使用我们刚刚编写的模板字符串创建一个提示模板。

79
00:04:54,840 --> 00:05:01,560
从提示模板中，

80
00:05:01,560 --> 00:05:06,120
你实际上可以提取原始提示，并意识到

81
00:05:06,120 --> 00:05:10,520
这个提示有两个输入变量，样式和文本，

82
00:05:10,520 --> 00:05:16,040
这些用花括号表示。

83
00:05:16,040 --> 00:05:20,200
这里也是我们指定的原始模板。

84
00:05:20,200 --> 00:05:22,760
事实上，如果我打印出来，

85
00:05:22,760 --> 00:05:27,800
它意识到它有两个输入变量，样式和文本。

86
00:05:27,800 --> 00:05:30,200
现在让我们指定样式。

87
00:05:30,200 --> 00:05:31,960
这是我想要的样式，

88
00:05:31,960 --> 00:05:33,800
将客户消息翻译成该样式。

89
00:05:33,800 --> 00:05:36,320
所以我要称之为客户样式。

90
00:05:36,320 --> 00:05:44,120
这是我之前的同一个客户电子邮件。

91
00:05:44,120 --> 00:05:50,960
现在，如果我创建

92
00:05:50,960 --> 00:05:55,520
客户消息，这将生成提示，

93
00:05:55,520 --> 00:05:59,560
并将在一分钟内传递给大型语言模型以获得响应。

94
00:05:59,560 --> 00:06:01,880
所以如果你想看看类型，

95
00:06:01,880 --> 00:06:04,400
客户消息实际上是一个列表。

96
00:06:04,400 --> 00:06:10,760
如果你看一下列表的第一个元素，

97
00:06:10,760 --> 00:06:16,880
这更或多或少是你期望它创建的提示。

98
00:06:16,880 --> 00:06:20,440
最后，让我们将此提示传递给LLM。

99
00:06:20,440 --> 00:06:22,560
所以我要调用聊天，

100
00:06:22,560 --> 00:06:25,040
我们之前设置的，

101
00:06:25,040 --> 00:06:28,480
作为OpenAI聊天GPT端点的参考。

102
00:06:28,480 --> 00:06:36,320
如果我们打印出客户响应的内容，

103
00:06:36,320 --> 00:06:38,800
那么它会给你返回，um，
 
104
00:06:38,800 --> 00:06:45,000
这段文本是从英语海盗语翻译成礼貌的美式英语。

105
00:06:45,000 --> 00:06:47,840
当然，你可以想象其他使用情况，

106
00:06:47,840 --> 00:06:53,400
客户的电子邮件是其他语言，这也可以用来

107
00:06:53,400 --> 00:06:58,400
翻译消息，以便英语为母语的人理解并回复。

108
00:06:58,400 --> 00:07:02,280
我鼓励你暂停视频并运行代码，还可以

109
00:07:02,280 --> 00:07:06,280
尝试修改提示，看看是否可以获得不同的输出。

110
00:07:06,280 --> 00:07:09,240
现在，让我们希望我们的客服代表

111
00:07:09,240 --> 00:07:11,800
用他们的原始语言回复客户。

112
00:07:11,800 --> 00:07:16,160
所以，让我们假设英语为母语的客服代表写了这个并说，

113
00:07:16,160 --> 00:07:18,240
嘿，客户，保修不包括，

114
00:07:18,240 --> 00:07:20,280
你的厨房清洁费，因为这是你的错，

115
00:07:20,280 --> 00:07:23,520
你忘记盖上盖子，误用了你的搅拌机。

116
00:07:23,520 --> 00:07:24,920
很遗憾，再见。

117
00:07:24,920 --> 00:07:26,320
不是很礼貌的消息，

118
00:07:26,320 --> 00:07:31,560
但是，让我们假设这是客服代表想要的。

119
00:07:31,720 --> 00:07:36,040
我们将指定

120
00:07:36,040 --> 00:07:39,480
服务消息将被翻译成这种海盗风格。

121
00:07:39,480 --> 00:07:45,120
所以我们希望它以礼貌的语气用英语海盗语说话。

122
00:07:45,120 --> 00:07:48,080
因为我们之前创建了那个提示模板，

123
00:07:48,080 --> 00:07:52,520
很酷的是我们现在可以重复使用那个提示模板并指定

124
00:07:52,520 --> 00:07:58,240
我们想要的输出样式是这个服务风格的海盗和这个服务回复的文本。

125
00:07:58,240 --> 00:08:01,240
如果我们这样做，

126
00:08:01,800 --> 00:08:05,200
那就是提示。

127
00:08:05,760 --> 00:08:09,160
如果我们提示，

128
00:08:09,160 --> 00:08:13,040
聊天GPT，这是它给我们的回应。

129
00:08:13,040 --> 00:08:18,080
啊，那里的伙计，我必须友好地告诉你，保修不包括

130
00:08:18,080 --> 00:08:21,200
你的厨房清洁费等等。

131
00:08:21,200 --> 00:08:23,520
是的，很遗憾，再见我的心爱的。

132
00:08:23,520 --> 00:08:27,600
所以你可能会想知道为什么我们使用提示模板而不是，

133
00:08:27,600 --> 00:08:28,920
你知道，只是一个F字符串？

134
00:08:28,920 --> 00:08:32,480
答案是，随着你构建复杂的应用程序，

135
00:08:32,480 --> 00:08:35,360
提示可能会非常长和详细。

136
00:08:35,360 --> 00:08:42,440
因此，提示模板是一个有用的抽象，可以帮助您在可以重复使用好的提示时重复使用它们。
 
137
00:08:42,440 --> 00:08:46,760
嗯，这是一个相对较长的提示示例，用于在线学习应用程序中对学生提交的作业进行评分。

138
00:08:46,760 --> 00:08:52,000
像这样的提示可能会很长，您可以要求LLM首先解决问题，然后以特定格式输出。

139
00:08:52,000 --> 00:08:57,560
将其包装在Lanchain提示中可以更轻松地重用此类提示。

140
00:08:57,560 --> 00:09:02,600
此外，您稍后会看到Lanchain为一些常见操作提供提示，

141
00:09:02,600 --> 00:09:08,720
例如摘要或问题回答或连接到SQL数据库，

142
00:09:08,720 --> 00:09:14,640
或连接到不同的API。

143
00:09:14,640 --> 00:09:20,520
因此，通过使用一些Lanchain内置的提示，

144
00:09:20,520 --> 00:09:22,280
您可以快速使应用程序运行而无需自己设计提示。

145
00:09:22,280 --> 00:09:25,880
Lanchain提示库的另一个方面是它还支持输出解析，

146
00:09:25,880 --> 00:09:29,640
我们将在一分钟内介绍。

147
00:09:29,640 --> 00:09:31,880
但是，当您使用LLM构建复杂应用程序时，

148
00:09:31,880 --> 00:09:37,840
通常会指示LLM以特定格式生成其输出，

149
00:09:37,840 --> 00:09:40,600
例如使用特定关键字。

150
00:09:40,600 --> 00:09:42,920
左侧的示例说明了使用LLM执行一种称为思维链推理的东西，

151
00:09:42,920 --> 00:09:46,840
使用React框架。

152
00:09:46,840 --> 00:09:52,600
但是不要担心技术细节，

153
00:09:52,600 --> 00:09:55,240
但关键是LLM正在思考什么，

154
00:09:55,240 --> 00:10:00,680
因为给LLM思考的空间，

155
00:10:00,680 --> 00:10:06,160
它通常可以得出更准确的结论。

156
00:10:06,160 --> 00:10:09,280
然后将动作作为关键字执行特定操作，

157
00:10:09,280 --> 00:10:15,560
然后观察以显示从该操作中学到的内容，依此类推。

158
00:10:15,560 --> 00:10:18,160
如果您有一个提示，指示LLM使用这些特定关键字，

159
00:10:18,160 --> 00:10:21,240
思考，动作和观察，

160
00:10:21,240 --> 00:10:25,520
那么这个提示可以与解析器配合使用，

161
00:10:25,520 --> 00:10:31,240
以提取已标记为这些特定关键字的文本。

162
00:10:31,240 --> 00:10:37,480
因此，这一起为指定LLM的输入提供了非常好的抽象，

163
00:10:37,480 --> 00:10:39,920
然后还可以使用解析器正确解释LLM给出的输出。
 
168
00:11:01,040 --> 00:11:08,680
因此，让我们回到使用Langchain的输出解析器的示例。

169
00:11:08,680 --> 00:11:14,160
在这个例子中，让我们看一下如何使用LLM输出JSON，

170
00:11:14,160 --> 00:11:17,280
并使用Langchain解析该输出。

171
00:11:17,280 --> 00:11:23,440
我将使用一个产品评论的运行示例来提取信息并以JSON格式格式化输出。

172
00:11:23,440 --> 00:11:28,800
这是一个期望的输出示例。

173
00:11:28,800 --> 00:11:33,920
这实际上是一个Python字典，

174
00:11:33,920 --> 00:11:36,720
其中产品是否为GIF，

175
00:11:36,720 --> 00:11:38,960
大规模的假，交付所需的天数为五天，

176
00:11:38,960 --> 00:11:41,840
价格值相当实惠。

177
00:11:41,840 --> 00:11:44,440
这是一个期望的输出示例。

178
00:11:44,440 --> 00:11:48,280
以下是客户评论以及尝试获得JSON输出的模板。

179
00:11:48,280 --> 00:11:50,720
以下是一个客户评论。

180
00:11:50,720 --> 00:11:57,160
它说，睡眠吹风机非常惊人。

181
00:11:57,160 --> 00:11:58,520
它有四个设置，蜡烛吹风机，

182
00:11:58,520 --> 00:12:00,600
温柔的微风，风城和龙卷风。

183
00:12:00,600 --> 00:12:02,480
它在两天内到达，正好是我妻子的周年礼物。

184
00:12:02,480 --> 00:12:04,800
我认为我妻子非常喜欢它，她一言不发。

185
00:12:04,800 --> 00:12:08,640
到目前为止，我是唯一使用它的人，等等。

186
00:12:08,640 --> 00:12:15,520
以下是评论模板。

187
00:12:15,520 --> 00:12:18,080
对于以下文本，提取以下信息，

188
00:12:18,080 --> 00:12:20,040
指定这是一个GIF。

189
00:12:20,040 --> 00:12:21,680
在这种情况下，是的，

190
00:12:21,680 --> 00:12:22,840
因为这是一个GIF。

191
00:12:22,840 --> 00:12:25,640
还有交付天数。

192
00:12:25,640 --> 00:12:27,160
需要多长时间才能交付？

193
00:12:27,160 --> 00:12:29,640
看起来在这种情况下，它在两天内到达。

194
00:12:29,640 --> 00:12:32,040
还有，价格值是多少？

195
00:12:32,040 --> 00:12:35,640
比睡眠吹风机稍微贵一些，等等。

196
00:12:35,640 --> 00:12:42,920
因此，评论模板要求LLM以客户评论作为输入，

197
00:12:42,920 --> 00:12:45,920
并提取这三个字段，

198
00:12:45,920 --> 00:12:48,360
然后将输出格式化为JSON，

199
00:12:48,360 --> 00:12:52,000
使用以下键。

200
00:12:52,000 --> 00:12:56,400
好的。

201
00:12:56,400 --> 00:13:01,080
以下是如何在Langchain中包装它。
 
204
00:13:01,080 --> 00:13:02,920
让我们导入聊天提示模板。

205
00:13:02,920 --> 00:13:04,760
实际上我们之前已经导入过了。

206
00:13:04,760 --> 00:13:06,520
所以从技术上讲，这一行是多余的，

207
00:13:06,520 --> 00:13:08,360
但我会再次导入它，

208
00:13:08,360 --> 00:13:10,680
然后从上面的评论模板创建提示模板。

209
00:13:10,680 --> 00:13:16,040
这是提示模板。

210
00:13:16,040 --> 00:13:19,480
现在，类似于我们早期使用提示模板的方式，

211
00:13:19,480 --> 00:13:23,680
让我们创建要传递给OpenAI端点的消息。

212
00:13:23,680 --> 00:13:32,000
创建OpenAI端点，调用该端点，然后让我们打印出响应。

213
00:13:32,000 --> 00:13:34,760
我鼓励您暂停视频并运行代码。

214
00:13:34,760 --> 00:13:39,000
然后就是这样了。

215
00:13:39,000 --> 00:13:42,960
它说GIF为true，交货时间为两天，

216
00:13:44,440 --> 00:13:46,520
价格值看起来也相当准确。

217
00:13:46,520 --> 00:13:49,000
但请注意，如果我们检查响应的类型，

218
00:13:49,000 --> 00:13:52,920
这实际上是一个字符串。

219
00:13:52,920 --> 00:14:02,280
看起来像JSON，看起来有键值对，

220
00:14:02,280 --> 00:14:04,040
但它实际上不是一个字典。

221
00:14:04,040 --> 00:14:07,960
这只是一个很长的字符串。

222
00:14:07,960 --> 00:14:09,480
所以我真正想做的是去响应内容，

223
00:14:09,480 --> 00:14:11,920
并从GIF键中获取值，这应该是true。

224
00:14:11,920 --> 00:14:14,720
但如果我运行这个，这应该会生成一个错误，因为，嗯，

225
00:14:14,720 --> 00:14:17,560
这实际上是一个字符串，这不是一个Python字典。

226
00:14:17,560 --> 00:14:21,080
所以让我们看看如何使用Langchain的解析器来做到这一点。

227
00:14:21,080 --> 00:14:24,040
我将从Langchain导入响应模式和结构化输出解析器。

228
00:14:24,040 --> 00:14:27,680
并且，我将告诉它我想要解析什么，通过指定这些响应模式。

229
00:14:27,680 --> 00:14:31,200
所以GIF模式被命名为GIF，

230
00:14:31,200 --> 00:14:39,560
这是描述。购买的物品是否作为礼物送给别人？回答true或yes，如果不是或未知，则为false等等。

231
00:14:39,560 --> 00:14:46,400
所以我有一个GIF模式，

232
00:14:46,400 --> 00:14:49,080
交货日期模式，价格值模式，

233
00:14:49,080 --> 00:14:50,200
然后让我们将它们全部放入列表中。

234
00:14:50,200 --> 00:14:52,720
现在我已经指定了这些模式，
 
241
00:15:08,760 --> 00:15:12,880
Langchain实际上可以直接给你提示，通过输出解析器告诉你要发送给LLM的指令。

242
00:15:12,880 --> 00:15:20,080
通过输出解析器告诉你要发送给LLM的指令，这样，如果我要打印格式指令，

243
00:15:20,080 --> 00:15:24,320
她有一套非常精确的LLM格式指令，可以生成输出，输出解析器可以处理。

244
00:15:24,840 --> 00:15:29,200
所以这是新的评论模板。

245
00:15:29,200 --> 00:15:33,640
评论模板包括Langchain生成的格式指令，因此也可以从评论模板中创建提示，

246
00:15:33,880 --> 00:15:37,400
然后创建将传递到OpenAI端点的消息。

247
00:15:37,400 --> 00:15:41,440
如果您想，您可以查看实际提示，

248
00:15:41,440 --> 00:15:50,720
它会告诉您如何提取字段，GIF、交货天数、价格值。

249
00:15:50,720 --> 00:15:57,960
这是文本，这是格式化指令。

250
00:15:57,960 --> 00:16:02,240
最后，如果我们调用OpenAI端点，

251
00:16:02,240 --> 00:16:07,440
让我们看看我们得到了什么响应。

252
00:16:07,440 --> 00:16:10,400
现在是这样的。

253
00:16:10,400 --> 00:16:15,400
现在，如果我们使用之前创建的输出解析器，

254
00:16:17,400 --> 00:16:25,240
您可以将其解析为输出字典。

255
00:16:25,240 --> 00:16:29,120
我们的打印应该是这样的。

256
00:16:29,120 --> 00:16:32,520
请注意，这是字典类型，而不是字符串。

257
00:16:33,320 --> 00:16:38,760
这就是为什么我现在可以提取与GIFs键相关联的值并获得true，

258
00:16:38,760 --> 00:16:46,040
或提取与交货天数相关联的值并获得2。

259
00:16:46,040 --> 00:16:49,080
或者您还可以提取与价格值相关联的值。

260
00:16:49,080 --> 00:16:57,000
因此，这是一种巧妙的方法，可以将您的LLM输出解析为Python字典，以使输出在下游处理中更容易使用。

261
00:16:57,000 --> 00:17:03,920
我鼓励您暂停视频并运行代码。

262
00:17:03,920 --> 00:17:08,640
这就是模型、提示和解析器。

263
00:17:08,640 --> 00:17:10,800
有了这些工具，希望您能轻松地重用自己的提示模板，

264
00:17:10,800 --> 00:17:14,040
与您合作的其他人分享提示模板，

265
00:17:14,040 --> 00:17:20,160
甚至使用Lanchain内置的提示模板，正如您刚才看到的，

266
00:17:20,160 --> 00:17:25,080
这是一种巧妙的方法，可以将您的LLM输出解析为Python字典，以使输出在下游处理中更容易使用。

267
00:17:25,080 --> 00:17:28,440
我鼓励您暂停视频并运行代码。

268
00:17:28,440 --> 00:17:31,160
这就是模型、提示和解析器。

269
00:17:31,160 --> 00:17:32,680
有了这些工具，希望您能轻松地重用自己的提示模板，

270
00:17:32,680 --> 00:17:37,640
与您合作的其他人分享提示模板，

271
00:17:37,640 --> 00:17:40,280
甚至使用Lanchain内置的提示模板，正如您刚才看到的，
 
275
00:17:45,040 --> 00:17:47,920
通常可以与输出解析器配对使用。

276
00:17:47,920 --> 00:17:53,280
这样，输入提示可以以特定格式输出，然后解析器将输出暂停以将数据存储在Python字典或其他数据结构中，以便于下游处理。

277
00:17:53,280 --> 00:17:57,800
我希望您在许多应用程序中都能找到这个有用。

280
00:18:06,080 --> 00:18:10,400
有了这个，让我们进入下一个视频，看看Lanchain如何帮助您构建更好的聊天机器人或使LLM的聊天更有效，

282
00:18:16,400 --> 00:18:36,400
通过更好地管理它到目前为止所记住的对话。