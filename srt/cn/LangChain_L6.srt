
 
1
00:00:00,000 --> 00:00:08,920
有时人们认为大型语言模型是一个知识库，

2
00:00:08,920 --> 00:00:11,920
好像它已经学会了记忆大量信息，

3
00:00:11,920 --> 00:00:14,880
也许是从互联网上获取的，所以当你问它一个问题时，

4
00:00:14,880 --> 00:00:16,380
它可以回答这个问题。

5
00:00:16,380 --> 00:00:19,340
但我认为，将大型语言模型视为推理引擎更加有用，

6
00:00:19,340 --> 00:00:22,980
你可以给它一些文本块或其他信息来源。

7
00:00:22,980 --> 00:00:27,140
然后大型语言模型，LLM，

8
00:00:27,140 --> 00:00:29,460
可能会使用从互联网上学到的背景知识，

9
00:00:29,460 --> 00:00:33,000
但是使用你提供的新信息来帮助你回答问题或推理内容或甚至决定下一步该做什么。

10
00:00:33,000 --> 00:00:36,620
这就是Lanchain的代理框架帮助你做的事情。

11
00:00:36,620 --> 00:00:41,100
代理可能是我最喜欢的Lanchain部分。

12
00:00:41,100 --> 00:00:45,180
我认为它们也是最强大的部分之一，

13
00:00:45,180 --> 00:00:48,340
但它们也是最新的部分之一。

14
00:00:48,340 --> 00:00:50,320
我们正在看到很多新的东西出现在这里，对于该领域的每个人来说都是新的。

15
00:00:50,320 --> 00:00:52,140
这应该是一个非常令人兴奋的课程，因为我们深入探讨

16
00:00:52,140 --> 00:00:56,020
代理是什么，如何创建代理，

17
00:00:56,020 --> 00:00:58,940
以及如何使用代理，

18
00:00:58,940 --> 00:01:01,180
如何为它们配备不同类型的工具，如

19
00:01:01,180 --> 00:01:02,500
内置于Lanchain中的搜索引擎，

20
00:01:02,500 --> 00:01:04,860
以及如何创建自己的工具，以便让代理与

21
00:01:04,860 --> 00:01:07,180
任何数据存储，任何API，

22
00:01:07,180 --> 00:01:11,480
任何你想让它们与之交互的函数。

23
00:01:11,480 --> 00:01:14,780
这是令人兴奋的前沿技术，

24
00:01:14,780 --> 00:01:16,860
但已经出现了一些重要的用例。

25
00:01:16,860 --> 00:01:19,460
因此，让我们开始吧。

26
00:01:19,460 --> 00:01:23,060
要开始使用代理，

27
00:01:23,060 --> 00:01:25,620
我们将像往常一样导入正确的环境变量。

28
00:01:25,620 --> 00:01:27,500
我们还需要安装一些软件包。

29
00:01:27,500 --> 00:01:32,420
因此，我们将使用DuckDuckGo搜索引擎和维基百科。

30
00:01:32,420 --> 00:01:35,100
因此，我们将要安装这些。

31
00:01:35,100 --> 00:01:39,020
我已经在我的环境中安装了这些，所以我不会运行这行。

32
00:01:39,020 --> 00:01:40,780
但如果你们没有，
 
36
00:01:46,360 --> 00:01:48,580
你应该取消注释那一行，

37
00:01:48,580 --> 00:01:51,300
运行它，然后你就可以开始了。

38
00:01:51,300 --> 00:01:56,060
然后我们将从Lanchain导入一些我们需要的方法和类。

39
00:01:56,060 --> 00:01:59,060
所以我们要导入一些加载工具的方法，

40
00:01:59,060 --> 00:02:02,340
这些是我们将连接语言模型的东西。

41
00:02:02,340 --> 00:02:05,020
我们将加载一个初始化代理的方法。

42
00:02:05,020 --> 00:02:07,820
我们将加载聊天Open AI包装器，

43
00:02:07,820 --> 00:02:09,500
我们将加载代理类型。

44
00:02:09,500 --> 00:02:14,220
所以代理类型将用于指定我们要使用的代理类型。

45
00:02:14,220 --> 00:02:16,540
Lanchain中有许多不同类型的代理。

46
00:02:16,540 --> 00:02:18,780
我们现在不会详细介绍所有这些。

47
00:02:18,780 --> 00:02:21,420
我们将选择一个并运行它。

48
00:02:21,420 --> 00:02:24,700
然后我们将初始化我们要使用的语言模型。

49
00:02:24,700 --> 00:02:30,500
同样，我们将使用它作为我们用来驱动代理的推理引擎。

50
00:02:30,500 --> 00:02:33,740
然后我们将加载我们要使用的工具。

51
00:02:33,740 --> 00:02:37,020
所以我们将加载DuckDuckGo搜索和维基百科，

52
00:02:37,020 --> 00:02:40,140
这些都是内置的Lanchain工具。

53
00:02:40,140 --> 00:02:42,980
最后，我们将初始化代理。

54
00:02:42,980 --> 00:02:44,780
我们将传递工具，

55
00:02:44,780 --> 00:02:47,700
语言模型和代理类型。

56
00:02:47,700 --> 00:02:49,340
所以这里我们使用聊天，

57
00:02:49,340 --> 00:02:51,460
零射击，反应，描述。

58
00:02:51,460 --> 00:02:54,060
我不会详细介绍这意味着什么。

59
00:02:54,060 --> 00:02:56,220
需要注意的重要事项是聊天。

60
00:02:56,220 --> 00:03:00,540
这是针对聊天模型进行优化的，然后是反应。

61
00:03:00,540 --> 00:03:05,620
反应是一种提示策略，可以从语言模型中引出更好的想法。

62
00:03:05,620 --> 00:03:09,220
我们还将设置处理解析错误等于true。

63
00:03:09,220 --> 00:03:11,620
如果您还记得第一课，

64
00:03:11,620 --> 00:03:17,140
我们谈论了输出解析器以及如何使用它们将LLM输出，

65
00:03:17,140 --> 00:03:22,060
这是一个字符串，并将其解析为我们可以在下游使用的特定格式。

66
00:03:22,060 --> 00:03:23,740
这在这里非常重要。

67
00:03:23,740 --> 00:03:25,620
当我们将LLM的输出，

68
00:03:25,620 --> 00:03:28,940
这是文本，并将其解析为特定的操作，

69
00:03:28,940 --> 00:03:32,700
以及语言模型应该采取的特定操作输入。
 
70
00:03:32,700 --> 00:03:34,300
现在让我们使用这个代理。

71
00:03:34,300 --> 00:03:38,940
让我们问一个关于最近事件的问题，这个模型在训练时不知道。

72
00:03:38,940 --> 00:03:41,060
所以让我们问一下2022年世界杯的情况。

73
00:03:41,060 --> 00:03:43,860
这里的模型是根据2021年左右的数据进行训练的。

74
00:03:43,860 --> 00:03:47,660
所以它不应该知道这个问题的答案。

75
00:03:47,660 --> 00:03:49,820
因此，它应该意识到需要使用工具来查找这个最近的信息。

76
00:03:49,820 --> 00:03:55,580
所以我们可以看到这里的代理意识到它需要使用DuckDuckGo搜索，然后查找2022年世界杯的获胜者。

77
00:04:05,340 --> 00:04:10,620
因此，它得到了一些信息。

78
00:04:10,620 --> 00:04:14,900
然后我们可以看到代理认为2022年世界杯还没有发生。

79
00:04:14,900 --> 00:04:18,060
所以这是一个很好的例子，说明代理仍然具有探索性。

80
00:04:18,060 --> 00:04:23,940
我们可以看到这里有很多关于2022年世界杯的信息，但它并没有完全意识到所有的事情都已经发生了。

81
00:04:23,940 --> 00:04:28,060
因此，它需要查找更多的信息。

82
00:04:28,060 --> 00:04:32,020
然后基于这些信息，它可以回答正确的答案，即阿根廷赢得了2022年世界杯。

87
00:04:47,380 --> 00:04:52,500
然后让我们问一个问题，它应该意识到需要使用维基百科。

88
00:04:52,500 --> 00:04:58,740
维基百科有很多关于特定人物和特定实体的信息，这些信息可以是很久以前的，不需要是当前的信息。

89
00:04:58,740 --> 00:05:02,980
所以让我们问一下美国计算机科学家Tom M. Mitchell写了哪本书。

90
00:05:02,980 --> 00:05:06,540
我们可以看到它意识到应该使用维基百科来查找答案。

91
00:05:06,540 --> 00:05:08,420
所以它搜索Tom M. Mitchell维基百科。

92
00:05:08,420 --> 00:05:12,700
然后再进行另一个跟进搜索，以确保它得到了正确的答案。

93
00:05:12,700 --> 00:05:16,020
所以它搜索Tom M. Mitchell机器学习，并得到更多的信息。

94
00:05:16,020 --> 00:05:19,460
然后基于这些信息，它最终能够回答Tom M. Mitchell写的教科书是《机器学习》。

98
00:05:29,660 --> 00:05:33,580
你可以在这里暂停视频，尝试输入不同的内容。

99
00:05:33,580 --> 00:05:38,380
到目前为止，我们已经使用了LinkedIn中预定义的工具。
 
100
00:05:38,380 --> 00:05:42,820
但代理的一个重要功能是可以将其连接到您自己的信息源、API和数据。

101
00:05:42,820 --> 00:05:45,100
您可以创建一个自定义工具，将其连接到您想要的任何内容。

102
00:05:45,100 --> 00:05:47,700
现在我们来创建一个工具，它将告诉我们当前的日期。

103
00:05:47,700 --> 00:05:50,700
首先，我们要导入这个工具装饰器。

106
00:05:57,500 --> 00:06:03,100
接下来，我们将编写一个名为“time”的函数，它接受任何文本字符串。

109
00:06:09,900 --> 00:06:15,540
它将通过调用日期时间返回今天的日期。

110
00:06:15,540 --> 00:06:20,660
除了函数的名称，我们还将编写一个非常详细的文档字符串。

111
00:06:20,660 --> 00:06:25,100
这是代理将用来知道何时调用此工具以及如何调用此工具的方式。

113
00:06:28,500 --> 00:06:32,060
例如，在这里，我们说输入应始终为空字符串。

116
00:06:37,460 --> 00:06:42,940
如果我们对输入有更严格的要求，例如，如果我们有一个应始终接受搜索查询或SQL语句的函数，

118
00:06:47,340 --> 00:06:49,060
现在我们将创建另一个代理。

119
00:06:49,060 --> 00:06:55,660
这次，我们将时间工具添加到现有工具列表中。

121
00:07:03,660 --> 00:07:08,140
它识别出需要使用时间工具，并在此指定。

126
00:07:18,740 --> 00:07:22,540
今天的日期是2023年5月21日。

128
00:07:26,860 --> 00:07:29,340
这就是代理的全部内容。

129
00:07:29,340 --> 00:07:34,740
这是LangChain中较新、更令人兴奋和更具实验性的部分之一。

130
00:07:34,740 --> 00:07:36,540
希望您喜欢使用它。
 
131
00:07:36,540 --> 00:07:40,540
希望它向您展示了如何使用语言模型作为推理引擎

132
00:07:40,540 --> 00:08:00,540
以执行不同的操作并连接到其他功能和数据源。