文档中的LLM
------------------

将LLM与文档结合的问题在于LLM一次只能审查几千个词，通常这对于大型文档或数据集来说是不足够的。

为了克服这个限制，我们有两个关键组成部分来帮助我们：

嵌入
----------

嵌入将文本转换为文本语义的数值表示，使具有相似内容的文本片段产生相似的向量。正是这些数值被放入向量存储中。

TXT -> 分块 -> 嵌入 -> [-0.003530，-0.010379，...，0.005863]
                                      /
                                     /
                                    /
                                   /
- 嵌入向量捕捉内容/含义
- 具有相似向量的文本具有相似的含义

示例：

1）我的狗罗弗喜欢追松鼠。
2）我的猫弗拉菲拒绝吃罐头食物。
3）雪佛兰Bolt可以在6.7秒内加速到60英里/小时。

1）-> 嵌入 -> [-0.003530，-0.010379，...，0.005863]
                                                   \
                                                    \__ 非常相似
                                                   /
                                                  /
2）-> 嵌入 -> [-0.003540，-0.010369，...，0.005265]
                                                   \
                                                    \__ 不相似
                                                   /
                                                  /
3）-> 嵌入 -> [-0.603530，-0.040329，...，0.705863]
                                                   比较

这使我们能够找到相似的文本，并只将其传递给LLM。

向量数据库
---------------
创建							向量数据库
            	 ______________________________________________
 分块 -> 嵌入 -> | [-0.003530，-0.010379，...，0.005863]，分块 |
/分块 -> 嵌入 -> | [-0.003540，-0.010369，...，0.005265]，分块 |
文本  ...       |											 |
文本  ...       |											 |
文本  ...       |											 |
文本  ...       |											 |
\ ...          |										    |
 分块 -> 嵌入 -> | [-0.603530，-0.040329，...，0.705863]，分块 |
                 -----------------------------------------------
                              嵌入向量                原始
                                                 分块

这个数据库存储了向量表示，传入的文档被分成较小的块，每个块都获得一个嵌入向量，然后将其与分块一起存储在数据库中。

当查询进来时，我们可以使用这个方法将查询与向量匹配。当查询到达时，嵌入会为查询生成向量，并使用向量数据库将最相似的向量与查询进行匹配。

					索引
						______________________________________________
                    /  | [-0.003530，-0.010379，...，0.005863]，分块 |
                   /   | [-0.003540，-0.010369，...，0.005265]，分块 | -> 相似
            	  /	   |	...										  |
查询 -> 嵌入       	   |	...										  |
            	  \	   |	...										  |
                   \   |	...										  |
                    \  | [-0.603530，-0.040329，...，0.705863]，分块 | -> 相似
						-----------------------------------------------

完成后，基于向量选择的分块可以发送给LLM。

使用LLM进行处理

				n个最相似 -> LLM -> 完成

n个最相似的值很可能适合LLM的上下文大小。

检索器
----------
可以使用向量存储本身返回一部分文档以发送给LLM。这些检索器可以采用不同的方法，并且您可以使用检索链中的选项来更改链的工作方式。

Stuff方法

	文档 + 提示 -> LLM -> 最终答案

	Stuffing是最简单的方法，您只需将所有数据填充到提示上下文中，然后传递给LLM。

	优点：它只进行一次调用，LLM可以一次访问所有数据。
	缺点：LLM有一个上下文长度，大型文档或许多文档将太大。

Map reduce
		  分块 -> LLM \
		/ 分块 -> LLM  \
	文档   ...			  LLM -> 最终答案
		\  ...          /
		  分块 -> LLM /

在Map Reduce方法中，将文档分成块，每个块传递给一个LLM，然后由最后一个LLM调用汇总所有结果。

	优点：处理速度快，并且能够适应任何数量/大小的文档
	缺点：需要多次调用，而且每个块都作为独立的文档处理，因此这种方法可能不适用于所有类型的文档。

细化（Refine）

		  分块 -> LLM \
		/ 分块 ------> LLM
	文档   ...		      \
		\  ...             \
		  分块 ----------> LLM -> 最终答案

在细化过程中，每个分块都传递给LLM，之前的所有分块的输出也传递给LLM，直到最后一个分块被处理并给出结果。

优点：逐步构建答案。
缺点：这需要几乎与Map reduce一样多的调用，并且由于它们是顺序执行的，可能会很慢。

Map rerank
		  分块 -> LLM -> 40 |
		/ 分块 -> LLM -> 91 |
	文档   ...			  	 |-> 选择最高分数 -> 最终答案
		\  ...               |
		  分块 -> LLM -> 33 |

这类似于Map reduce，但使用分数来选择结果。您需要让LLM知道如何评分。

优点：处理速度快，扩展性好。
缺点：这需要很多LLM调用。